{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 00) Overview\n",
        "\n",
        "The final project will be similar to assignments 3 and 4, however, we will be asking you to **plan and complete** *your own* analysis.\n",
        "\n",
        "## Requirements:\n",
        "You will need to decide *and detail* ONE OF:  \n",
        "a) a novel analysis/technique to try on the Myeloid vs non-Myeloid dataset   \n",
        "b) a new dataset to re-run the Assignment 3 and/or 4 code on  \n",
        "c) an alternative analysis \n",
        "\n",
        "You do not need both a new dataset + a new method, but you are certainly allowed to do both (as an alternative analysis, c) ). If you would like to submit an alternative analysis, please contact eyes and/or Prof. Lareau (unless you simply intend to do both a) and b) ). \n",
        "\n",
        "## Example(s):\n",
        "We've hinted at batch effects over the course of the semester, but we have not used it thus far. \n",
        "\n",
        "One sample project you can do is choose a batch effects correction technique, e.g. Combat (a 2007 technique as seen in the R package here https://rdrr.io/bioc/sva/man/ComBat.html -- for a Python version there is pyComBat among others), then apply it to the Myeloid vs non-Myeloid data (which are different batches, the input batch variable for combat would be a vector like `[1 1 1 1 1 ... 0 0 0 0]` where 1 corresponds to a cell from Myeloid and 0 from non-Myeloid, etc. \n",
        "\n",
        "You will then need to compare the results (clustering, differential gene expression, etc) to the data without batch effects and note any differences between the figures, etc. \n",
        "\n",
        "Obviously, Combat is a slightly antiquated method, so if you choose to do it, try to look up a more advanced technique and explain what you might expect the benefits of the new method would be and *why* (i.e. is there some nonlinear effect, if so, what kind and where?)\n",
        "\n",
        "For method ideas: Other examples might include using a sparsity imputation technique (e.g. MAGIC https://www.krishnaswamylab.org/projects/magic) -- feel free to contact eyes or Prof. Lareau for more ideas/suggestions about methods!\n",
        "\n",
        "For datsaets: Count-based matrices are ideal to look for (ideally not too big, these might be very slow or have engineering issues) -- Tabula Muris (https://tabula-muris.ds.czbiohub.org/) or the Chan-Zuckerberg Human Cell Atlas (https://www.humancellatlas.org/portals/) are good places to start looking :) \n",
        "\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "For full credit, you will need to turn in:\n",
        "\n",
        "1) Your .ipynb notebook containing your analysis code.   \n",
        "2) A matching pdf of the notebook with figures partially visible.   \n",
        "3) a 2-3 page .txt, .doc(x), or PDF writeup of your findings, including but not limited to:   \n",
        "* why you chose your method and/or dataset of interest. Note: if you are using the Myeloid data provided or the Assignment 3/4 analysis instead of doing **c) an alternative analysis** above, you **must** justify your method/dataset selection with an explanation of why it is interesting or good data.   \n",
        "* a summary of your dataset (columns, cell count, etc) or method chosen. If there is a paper/pre-print for your dataset/method, please provide a citation and quick summary of the paper.  \n",
        "* 2-3 key figures with labeled + appropriate axes, titles, and captions (hint: add a textbox in Word (etc) for the caption to make it easier).  \n",
        "* a results section with 2+ findings and discussion as to what the findings mean / why they are important\n",
        "* try to note a limitation/possible room for improvements in each part of your response! \n",
        "\n"
      ],
      "metadata": {
        "id": "unyeN4fbGYtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0) INSTALLS\n",
        "\n",
        "1. Using a mounted drive (or local installation) is recommended \n",
        "2. The following code will install packages for our analysis this week; installations will take >= 6 minutes and *it's best to not spend an hour of your life re-installing it* :)\n",
        "\n",
        "See Debug tips if you have installation errors"
      ],
      "metadata": {
        "id": "z50R2OgqDkwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## mount Google drive (optional, recommended)\n",
        "## DEBUG TIP ##\n",
        "## when restarting session, be sure to run first two lines (else you can comment out)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/bioe_190_290/\n",
        "!mkdir -p /content/drive/MyDrive/bioe_190_290/pythonpkg/\n",
        "!mkdir -p /content/drive/MyDrive/bioe_190_290/project/\n",
        "\n",
        "## set working dir (feel free to change)\n",
        "%cd /content/drive/MyDrive/bioe_190_290/project/"
      ],
      "metadata": {
        "id": "HVKPl4YM_EpH",
        "outputId": "6652a820-52da-421e-f550-44a6cce4871e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/bioe_190_290/assignment4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "## NOTE: %%capture removes the outputs -- if you have an import/install error (etc)\n",
        "## you should remove the line. Otherwise, let this cell run for ~10 minutes on your \n",
        "## first installation (on subsequent runs this should be instantaneous as it skips)\n",
        "\n",
        "pkg_contents = !ls /content/drive/MyDrive/bioe_190_290/pythonpkg/\n",
        "do_install = len(pkg_contents) < 10 \n",
        "\n",
        "## this umap dependency has to be reinstalled each time (it's quick!)\n",
        "!pip install pynndescent \n",
        "\n",
        "if do_install:\n",
        "  !pip install --target=/content/drive/MyDrive/bioe_190_290/pythonpkg/ scprep phate tasklogger igraph\n",
        "  !pip install --target=/content/drive/MyDrive/bioe_190_290/pythonpkg/ umap-learn magic-impute louvain\n",
        "\n",
        "pheno_install = !ls /content/drive/MyDrive/bioe_190_290/pythonpkg | grep pheno\n",
        "pheno_install = len(pheno_install) < 1\n",
        "\n",
        "if pheno_install:\n",
        "  !pip install --target=/content/drive/MyDrive/bioe_190_290/pythonpkg/ git+https://github.com/dpeerlab/phenograph.git\n",
        "\n",
        "## this is IMPORTANT -- otherwise python won't be able to find \n",
        "import sys\n",
        "if sys.path[0] != '/content/drive/MyDrive/bioe_190_290/pythonpkg/':\n",
        "  sys.path.insert(0, '/content/drive/MyDrive/bioe_190_290/pythonpkg/')"
      ],
      "metadata": {
        "id": "wLrvnfH9EM9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rinT1SUmlj64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff4657b-3eba-40a7-f338-2856bbe5aa74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: This package has been superseded by the `leidenalg` package and will no longer be maintained. Please upgrade to the `leidenalg` package.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scprep, phate, umap ## sometimes this takes 2-3 minutes in a new session  \n",
        "\n",
        "import sklearn\n",
        "import sklearn.cluster\n",
        "import sklearn.manifold\n",
        "import graphtools as gt\n",
        "import magic\n",
        "import phenograph\n",
        "import louvain\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO -- if you need to install a pip package and would like it to be saved \n",
        "## in Google drive, use the following code:\n",
        "\n",
        "## for github, bash, or apt-get packages this should also work\n",
        "## conda would require modifications\n",
        "\n",
        "# this checks if my_install is present in drive (to prevent re-installation )\n",
        "my_install = !ls /content/drive/MyDrive/bioe_190_290/pythonpkg | grep ..my dir..\n",
        "my_install = len(my_install) < 1 \n",
        "\n",
        "if my_install:\n",
        "  !pip install --target=/content/drive/MyDrive/bioe_190_290/pythonpkg/ git+https://github.com/dpeerlab/phenograph.git\n",
        "\n",
        "import sys\n",
        "if sys.path[0] != '/content/drive/MyDrive/bioe_190_290/pythonpkg/':\n",
        "  sys.path.insert(0, '/content/drive/MyDrive/bioe_190_290/pythonpkg/')\n",
        "\n",
        "import ..package name.."
      ],
      "metadata": {
        "id": "mQmnvhVjEXnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUF17reyacVy"
      },
      "source": [
        "<a id='loading'></a>\n",
        "## 1. OPTIONAL: Loading preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "\n",
        "## this will copy your preprocessed data from the Assignment 3 folder\n",
        "## if you are uploading ther bCourses version (etc) this should not have an error \n",
        "## (unless you are somehow in the wrong directory)\n",
        "if !(test -f \"data.pickle.gz\"); then\n",
        "    cp ../assignment4/data.pickle.gz .\n",
        "fi\n",
        "\n",
        "if !(test -f \"metadata.pickle.gz\"); then\n",
        "    cp ../assignment4/metadata.pickle.gz .\n",
        "fi"
      ],
      "metadata": {
        "id": "csELr4dk67KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiCD66_C22Ur"
      },
      "outputs": [],
      "source": [
        "## load saved data (mount drive if not found or upload from bCourses)\n",
        "data = pd.read_pickle('data.pickle.gz')\n",
        "metadata = pd.read_pickle('metadata.pickle.gz')\n",
        "\n",
        "## we will rerun PCA so that you can visualize the clustering process\n",
        "data_pca = scprep.reduce.pca(data, n_components=50, method='dense')\n",
        "data_pca.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvsEm0zaGWFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lhLGxe5GWXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO your code here"
      ],
      "metadata": {
        "id": "aV9qQ39xGWar"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}